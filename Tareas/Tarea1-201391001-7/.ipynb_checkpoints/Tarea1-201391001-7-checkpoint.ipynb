{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cyHnKzqdeP73"
   },
   "source": [
    "<img src=\"escudo_utfsm.gif\" style=\"float:right;height:100px\">\n",
    "<img src=\"IsotipoDIisocolor.png\" style=\"float:left;height:100px\">\n",
    "<center>\n",
    "    <h1> ILI286 - Computación Científica II</h1>\n",
    "    <h1> Tarea 1: Deflation y Matrices Sparse </h1> \n",
    "    <h3> [S]cientific [C]omputing [T]eam 2019</h3>\n",
    "    <h3> Guillermo Godoy / 201391001-7</h3>\n",
    "</center>\n",
    "<p>\n",
    "<center>Agosto 2019 - v1.0 </center>\n",
    "</p>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.sparse as sparse\n",
    "from time import time\n",
    "from scipy import sparse\n",
    "import sys\n",
    "from scipy.sparse import lil_matrix\n",
    "from scipy.sparse import dok_matrix\n",
    "from scipy.sparse import csr_matrix\n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wosjMLgZeP79"
   },
   "source": [
    "## Contexto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bZH1FuvIebrD"
   },
   "source": [
    "Esta tarea tiene como objetivo aplicar los contenidos vistos en clase, respecto a métodos numéricos para obtener valores y vectores propios. Además, esta instancia servirá para recordar (o aprender) el uso de *Jupyter Notebook*, junto con las principales bibliotecas del curso: *Numpy* y *Scipy*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZxTtGo5FXNfa"
   },
   "source": [
    "## Sección 1: Algoritmo Deflation (30 puntos)\n",
    "\n",
    "Se discutió en clases que una de las principales propiedades que tienen las matrices simétricas es que\n",
    "\n",
    "* Sus valores propios son reales.\n",
    "* Sus vectores propios son ortogonales.\n",
    "\n",
    "Sabemos que por medio de *Power Iteration* e *Inverse Power Iteration*, podemos rescatar algunos de los valores propios y vectores propios. Mediante *Normalized Simultaneous Iteration* o *Unshifted QR*, podemos extraer todos los valores y vectores propios al mismo tiempo. Ahora veremos un método distinto para extraer los valores y vectores propios, uno por uno."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consideremos una matriz $A \\in \\mathbb{R}^{n \\times n}$ simétrica cuyos valores propios son $\\lambda_i$ (por simplicidad, consideraremos que también son todos positivos) y sus vectores propios son $\\mathbf{v}_i$, para $i \\in \\{1, 2, \\dots, n\\}$. Considere además que $\\lambda_i > \\lambda_j$, para todo $i < j$, es decir, los valores propios están ordenados. Considere ahora la matriz $A_1$ definida como:\n",
    "\n",
    "$$\n",
    "    A_1 = A - \\lambda_1\\mathbf{v}_1\\,\\mathbf{v}_1^T.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. (5 puntos)** Demuestre que los vectores propios de $A$ también son los vectores propios de $A_1$. ¿Cuáles son los valores propios de $A_1$?\n",
    "\n",
    "R:\n",
    "Supuesto: Los vectores propios son $\\mathbf{v}_i$, para $i \\in \\{1, 2, \\dots, n\\}$, solo consideraremos los vectores normalizados.\n",
    "\n",
    "Tenemos por propiedad: \n",
    "$$\n",
    "\\begin{align}\n",
    "A\\mathbf{v}_i & = \\lambda_i\\mathbf{v}_i \\\\ \n",
    "A\\mathbf{v}_1 & = \\lambda_1\\mathbf{v}_1 \\\\ \n",
    "A_1\\mathbf{v}_{A_1} & = \\lambda_{A_1}\\mathbf{v}_{A_1}\n",
    "\\end{align}\n",
    "$$\n",
    "Donde tenemos que obtener:\n",
    "$$\n",
    "\\begin{align}\n",
    "\\mathbf{v}_{A_1} & = \\mathbf{v}_i\n",
    "\\end{align}\n",
    "$$\n",
    "Modificamos la Matriz $A_1$ dada anteriormente de la siguiente forma:\n",
    "$$\n",
    "\\begin{align}\n",
    "A_1 &= A - \\lambda_1\\mathbf{v}_1\\,\\mathbf{v}_1^T \\\\ \n",
    "A_1\\mathbf{v}_i&=A\\mathbf{v}_i-A\\mathbf{v}_1\\,\\mathbf{v}_1^T\\mathbf{v}_i \\\\\n",
    "\\end{align}\n",
    "$$\n",
    "Tenemos 2 casos:\n",
    "\n",
    "Con $i\\neq 1 $ (Dado que $A=A^T$ y $\\lambda_i > \\lambda_j$ entonces $$v_1^Tv_i=0$$ (Vectores propios con valores propios distintos son ortogonales))\n",
    "$$\n",
    "\\begin{align}\n",
    "A_1\\mathbf{v}_i&=A\\mathbf{v}_i-A\\mathbf{v}_1\\,\\mathbf{v}_1^T\\mathbf{v}_i \\\\\n",
    "A_1\\mathbf{v}_i&=A\\mathbf{v}_i\\\\\n",
    "A_1\\mathbf{v}_i&=\\lambda_i\\mathbf{v}_i\n",
    "\\end{align}\n",
    "$$\n",
    "Con $i=1$\n",
    "$$\n",
    "\\begin{align}\n",
    "A_1\\mathbf{v}_1&=A\\mathbf{v}_1-A\\mathbf{v}_1\\,\\mathbf{v}_1^T\\mathbf{v}_1 \\\\\n",
    "A_1\\mathbf{v}_1&=A\\mathbf{v}_1(1-\\mathbf{v}_1^T\\mathbf{v}_1)\\\\\n",
    "\\mathbf{v}_1^T\\mathbf{v}_1 &= \\parallel \\mathbf{v}_1\\parallel_2^2\\\\\n",
    "\\parallel \\mathbf{v}_1\\parallel_2^2&= 1\\\\\n",
    "A_1\\mathbf{v}_1&=0\\mathbf{v}_1\n",
    "\\end{align}\n",
    "$$\n",
    "Por lo que obtenemos que $A_1$ tiene los mismos vectores propios de $A$ y tiene los mismos valores propios a excepción del primero, donde el primer valor propio de $A_1$ es cero"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. (10 puntos)** El proceso anterior, denominado *Deflation*, puede repetirse iterativamente para construir un algoritmo iterativo que permita encontrar los valores y vectores propios en sucesión. El algoritmo, paso a paso, puede definirse como:\n",
    "\n",
    "1. Se define $A_0 = A$, $\\lambda_0 = 0$ y $\\mathbf{v}_0 = \\mathbf{0}$.\n",
    "2. Para $i \\in \\{1, 2, \\dots, n\\}$\n",
    "    1. Se define $A_i = A_{i-1} - \\lambda_{i-1}\\mathbf{v}_{i-1}\\,\\mathbf{v}_{i-1}^T$.\n",
    "    2. Se encuentra el valor y vector propio dominante de $A_{i}$, denotados por $\\lambda_{i}$ y $\\mathbf{v}_{i}$, respectivamente.\n",
    "3. Se retorna el conjunto $\\{\\lambda_1, \\lambda_2, \\dots, \\lambda_n\\}$ y $\\{ \\mathbf{v}_{1}, \\mathbf{v}_{2}, \\dots, \\mathbf{v}_{n}\\}$.\n",
    "\n",
    "Implemente la función `deflation`, el cual aplicará el algoritmo *Deflation* mediante el uso de *Power Iteration*. Esta función debe recibir como parámetros:\n",
    "* La matriz $A$.\n",
    "* Un *initial guess* $\\mathbf{x}_0$.\n",
    "* Un número de iteraciones.\n",
    "\n",
    "La función debe retornar una lista con los valores propios encontrados y una lista de los vectores propios encontrados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "Program 12.1 Power iteration\n",
    "Computes dominant eigenvector of square matrix\n",
    "Input: matrix A, initial (nonzero) vector x, number of steps k\n",
    "Output: dominant eigenvalue lam, eigenvector u\n",
    "'''\n",
    "def power_iteration(A, x, k, verbose=False):\n",
    "   \n",
    "    for j in range(k):\n",
    "        u = x/np.linalg.norm(x)\n",
    "        x = np.dot(A, u)\n",
    "    lam = np.dot(u, x)\n",
    "    u = x/np.linalg.norm(x)\n",
    "    return (lam, u)\n",
    "\n",
    "\n",
    "'''\n",
    "Compute all the eigenvalues and eigenvectors using Deflation procedure.\n",
    "Input:\n",
    "A - (n x n matrix) Matrix to compute its eigenvalues and eigenvectors\n",
    "x0 - (array) Initial guess for Power Iteration\n",
    "it - (integer) Number of iteration for Power Iteration.\n",
    "Output:\n",
    "eig_values - (list) A list with the eigenvalues found by the algorithm\n",
    "eig_vectors - (list) A list with the eigenvectors found by the algorithm\n",
    "'''\n",
    "def deflation(A, x0, it):\n",
    "    eig_values = []\n",
    "    eig_vectors = []\n",
    "    lam=0\n",
    "    n = A.shape[0]\n",
    "    #v = np.zeros((n,1))\n",
    "    v=0\n",
    "    for i in range(n):\n",
    "        #A -= lam*np.dot(v,v.T)\n",
    "        A -= lam*v*np.transpose([v])\n",
    "        lam,v = power_iteration(A, x0, it)\n",
    "        eig_values.append(lam)\n",
    "        eig_vectors.append(v)\n",
    "    return eig_values, eig_vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para probar su algoritmo, utilice la función `generate_matrix` que construye una matriz simétrica a partir de una lista de valores propios específicos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "[2, 4, 8, 16, 32, 64, 128, 256, 512, 1024, 2048, 4096]\n",
      "[9.999999999999998, 9.0, 8.0, 7.0000000000000036, 6.0, 5.0000000000000036, 3.999999999999999, 3.000000000000001, 1.9999999999999996, 1.0000000000000004]\n",
      "[1.0000000000000004, -1.8846865067248437e-15, -1.6302029670098922e-15, -1.1324692493066439e-15, -8.730118902266693e-16, -4.3186236596426137e-16, -7.812894579662378e-17, -7.327850282731556e-17, 5.533214947236848e-17, -8.311585499942047e-17]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Given a list of n real vaues, returns a symmetric matrix whose eigenvalues are the given values.\n",
    "Input:\n",
    "eig_values - (list) list of n real values that will be used as eigenvalues\n",
    "Output: \n",
    "A - (n x n matrix) A symmetric matrix whose eigenvalues equals the values in eig_values list\n",
    "Q - (n x n matrix) An orthonormal matrix whose columns are the eigenvectors\n",
    "eig_values (list) A list with eigenvalues of A. It is the same list given as input.\n",
    "'''\n",
    "def generate_matrix(eig_values):\n",
    "    n = len(eig_values)\n",
    "    Q, _ = np.linalg.qr(np.random.rand(n, n))\n",
    "    L = np.diag(eig_values)\n",
    "    A = np.dot(Q, np.dot(L, Q.T))\n",
    "    return A, Q, eig_values\n",
    "eig_values1 = []\n",
    "eig_values2 = []\n",
    "for i in range(10):\n",
    "    eig_values1.append(i+1)\n",
    "A1,Q1,eig_values1=generate_matrix(eig_values1)\n",
    "\n",
    "for i in range(12):\n",
    "    eig_values2.append(2**(i+1))\n",
    "A2,Q2,eig_values2=generate_matrix(eig_values2)\n",
    "print (eig_values1)\n",
    "print (eig_values2)\n",
    "\n",
    "x01=np.ones(A1.shape[0])\n",
    "values1,vectores1=deflation(A1, x01, 1000)\n",
    "print(values1)\n",
    "\n",
    "x02=np.ones(A2.shape[0])\n",
    "values2,vectores2=deflation(A1, x01, 1000)\n",
    "print(values2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Genere matrices con los siguientes valores propios:\n",
    "* $\\{1, 2, \\dots, 10\\}$.\n",
    "* $\\{2, 2^2, 2^3, \\dots, 2^{12}\\}$.\n",
    "\n",
    "Utilice las matrices generadas para probar su algoritmo. Su tarea será probada con otras matrices, pero puede utilizar estas para verificar la correctitud de su algoritmo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. (15 puntos)** Implemente el algoritmo *Normalized Simultaneous Iteration* (NSI). Genere matrices de los siguientes tamaños, utilizando la función `generate_matrix`:\n",
    "\n",
    "* $100 \\times 100$.\n",
    "* $1000 \\times 1000$.\n",
    "* $10000 \\times 10000$.\n",
    "* $15000 \\times 15000$.\n",
    "\n",
    "Estime teóricamente cuanta memoria requiere cada uno de los algoritmos. Además, ejecute ambos algoritmos sobre las matrices generadas y mida el tiempo de ejecución. Concluya respecto a los resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A100 100\n",
      "A1000 1000\n",
      "A10000 10000\n",
      "Matriz de:  100 x 100\n",
      "Tiempo:  0:00:00.093758  para deflation con  100  iteraciones\n",
      "Tiempo:  0:00:00.078132  para NSI con  100  iteraciones\n",
      "Matriz de:  1000 x 1000\n",
      "Tiempo:  0:00:24.329952  para deflation con  100  iteraciones\n",
      "Tiempo:  0:00:13.501013  para NSI con  100  iteraciones\n",
      "Matriz de:  10000 x 10000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-87-5e20887dc231>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[0mrevisar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[0mrevisar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA1000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m \u001b[0mrevisar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA10000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-87-5e20887dc231>\u001b[0m in \u001b[0;36mrevisar\u001b[1;34m(A, k)\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0mx0\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[0mti\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m     \u001b[0mvalues1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvectores1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdeflation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m     \u001b[0mtf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[0mtiempo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mti\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-505ec5ad2004>\u001b[0m in \u001b[0;36mdeflation\u001b[1;34m(A, x0, it)\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[1;31m#A -= lam*np.dot(v,v.T)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m         \u001b[0mA\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[0mlam\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m         \u001b[0mlam\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpower_iteration\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m         \u001b[0meig_values\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlam\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m         \u001b[0meig_vectors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-505ec5ad2004>\u001b[0m in \u001b[0;36mpower_iteration\u001b[1;34m(A, x, k, verbose)\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mu\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mu\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m     \u001b[0mlam\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mu\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def NSI(A, k):\n",
    "    Q = np.identity(A.shape[0])\n",
    "    for i in range(k):\n",
    "        Q, R = np.linalg.qr(np.dot(A, Q))\n",
    "    return (np.diag(np.dot(np.dot(Q.transpose(),np.diag(A)),Q)))\n",
    "\n",
    "for i in range(15000):\n",
    "    eig_values1.append(i+1)\n",
    "A100,Q1,_=generate_matrix(eig_values1[:100])\n",
    "print(\"A100\",A100.shape[0])\n",
    "\n",
    "A1000,Q1,_=generate_matrix(eig_values1[:1000])\n",
    "print(\"A1000\",A1000.shape[0])\n",
    "A10000,Q1,_=generate_matrix(eig_values1[:10000])\n",
    "print(\"A10000\",A10000.shape[0])\n",
    "#A15000,Q1,_=generate_matrix(eig_values1)\n",
    "#print(\"A15000\",A15000.shape[0])\n",
    "\n",
    "def revisar(A,k):\n",
    "    print(\"Matriz de: \",A.shape[0],\"x\",A.shape[0])\n",
    "    \n",
    "    x0=np.ones(A.shape[0])\n",
    "    ti = time()\n",
    "    values1,vectores1=deflation(A, x0, k)\n",
    "    tf = time()\n",
    "    tiempo = tf-ti\n",
    "    print(\"Tiempo: \",str(datetime.timedelta(seconds=tiempo)),\" para deflation con \",k,\" iteraciones\")\n",
    "    ti = time()\n",
    "    values1=NSI(A, k)\n",
    "    tf = time()\n",
    "    tiempo = tf-ti\n",
    "    print(\"Tiempo: \",str(datetime.timedelta(seconds=tiempo)),\" para NSI con \",k,\" iteraciones\")\n",
    "\n",
    "revisar(A100,100)\n",
    "revisar(A1000,100)\n",
    "#revisar(A10000,100)\n",
    "#revisar(A15000,100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teoricamente:\n",
    "deflation: ocupa la matriz n * n ($n^2$) + los 2 vectores (eig_values y eig_vectors) el vector eig_values es de n y el eig_vectors es de n * n ($n^2$) dado que en cada iteracion guarda el vector propio asociado a cada valor propio. En total es\n",
    "$(n^2 + n + n^2)*8[B]$ . Nota: el total es la max capacidad de memoria que puede ocupar dado que los vectores eig_values y eig_vectors, solo van a llegar a su max capacidad en la ultima iteracion.\n",
    "\n",
    "NSI: ocupa la matriz n * n ($n^2$) y hace una desconpocicion QR de una matiz cuadrada dando Q y R del mismo tamaño n * n.\n",
    "En total es $3(n^2)*8[B]$ el cual es constante (el tamaño de memoria a utilizar) en toda la ejeccion.\n",
    "\n",
    "En tiempo de ejecucion NSI se demora menos que deflation, esto se debe principalmente a que en deflation hacemos el calculo de power_iteration, solo para obtener el mayor valor propio de la matriz que estamos trabajando en ese momento, y luego tenemos que generar una nueva matriz resultando de un calculo con la anterior y el resultado obtenido, por ende tenemos que estar calculando muchos valores preopios de \"distintas\" matrizes para lograr obtener todos los valores propios de la matriz original. En cambio en NSI se trabaja sobre la misma matriz y solo hay que generar una descompocicion QR sobre la matriz original y el Q anterior, estimamos más eficientemente la matriz diagonal que contiene los valores propios.\n",
    "NOTA: Solo se pudo evaluar con 100x100 y 1000x1000. Ya con 10000 se demoro demaciado en responder, lo mismo al generar la matriz de 15000x15000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sección 2: Uso de matrices *Sparse* (60 puntos)\n",
    "\n",
    "Cuando una matriz es de tipo *Sparse*[1], es posible trabajar sobre matrices de mayor tamaño, debido a que se evita el almacenamiento de valores *innecesarios* (en este caso, los ceros)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. (5 puntos)** Implemente la función `read_sparse_matrix` que reciba la ruta a un archivo de texto plano que contiene una matriz *sparse*, y construya la matriz respectiva utilizando una estructura de datos especializada para matrices *sparse*[2]. El formato del archivo será:\n",
    "* La primera línea del archivo contendrá un solo número `N`, donde `N` indica el tamaño de la matriz (matriz de tamaño `N`$\\times$`N`).\n",
    "* Cada una de las siguientes líneas contiene 3 números separados por espacios, que indicarán las entradas no nulas de la matriz. Si la línea contiene los números `i j a`, esto indica que en la fila `i` y columna `j`, la matriz tiene un coeficiente con valor `a`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de 10000\n",
      "Al ser sparse se guarda en memoria 0.08 MB \n",
      "Si no fuera sparse se guardarian 762.94MB\n",
      "Matriz de 20000\n",
      "Al ser sparse se guarda en memoria 0.15 MB \n",
      "Si no fuera sparse se guardarian 3051.76MB\n",
      "Matriz de 50000\n",
      "Al ser sparse se guarda en memoria 0.38 MB \n",
      "Si no fuera sparse se guardarian 19073.49MB\n",
      "Nota: hay diferencia en memoria al utilizar distintos metodos de creacion de matrices sparse, en mi caso utilize lil_matrix\n"
     ]
    }
   ],
   "source": [
    "\n",
    "'''\n",
    "Read a file in the specified format to build a Sparse Matrix.\n",
    "Input:\n",
    "path - (string) A path to a file.\n",
    "Output:\n",
    "A - (N x N matrix) The matrix in a sparse format.\n",
    "'''\n",
    "def read_sparse_matrix(path):\n",
    "    txt = open(path)\n",
    "    sw=False\n",
    "    for line in txt.readlines():\n",
    "        if (sw):\n",
    "            #print(line)\n",
    "            Datos=line.strip().split()\n",
    "            i=int(Datos[0])\n",
    "            j=int(Datos[1])\n",
    "            value=float(Datos[2])\n",
    "            A[i, j]=value\n",
    "        else:\n",
    "            N=int(line)\n",
    "            print(\"Matriz de\",N)\n",
    "            A = lil_matrix((N, N))\n",
    "            #A = dok_matrix((N, N))\n",
    "            #A = csr_matrix((N, N))\n",
    "            sw=True\n",
    "    txt.close()\n",
    "    return A\n",
    "\n",
    "M10000=read_sparse_matrix(\"matrix_10000.txt\")\n",
    "size = M10000.data.nbytes\n",
    "print('Al ser sparse se guarda en memoria {:.2f} MB '.format(size / 1024 ** 2))\n",
    "print('Si no fuera sparse se guardarian {:.2f}MB'.format((8*10000**2) / 1024 ** 2))\n",
    "M20000=read_sparse_matrix(\"matrix_20000.txt\")\n",
    "size = M20000.data.nbytes\n",
    "print('Al ser sparse se guarda en memoria {:.2f} MB '.format(size / 1024 ** 2))\n",
    "print('Si no fuera sparse se guardarian {:.2f}MB'.format((8*20000**2) / 1024 ** 2))\n",
    "M50000=read_sparse_matrix(\"matrix_50000.txt\")\n",
    "size = M50000.data.nbytes\n",
    "print('Al ser sparse se guarda en memoria {:.2f} MB '.format(size / 1024 ** 2))\n",
    "print('Si no fuera sparse se guardarian {:.2f}MB'.format((8*50000**2) / 1024 ** 2))\n",
    "print('Nota: hay diferencia en memoria al utilizar distintos metodos de creacion de matrices sparse, en mi caso utilize lil_matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargue las matrices adjuntas en los archivos `matrix_10000.txt`, `matrix_20000.txt` y `matrix_50000.txt`, de dimensiones $10000 \\times 10000$, $20000 \\times 20000$ y $50000\\times50000$ respectivamente, utlizando la función `read_sparse_matrix`. Considerando *double precision* para los números de punto flotante, indique cuánta memoria utilizarían estas matrices si fuesen cargadas utilizando arreglos bidimensionales o estructuras no-especializadas para matrices *sparse*. ¿Existe alguna diferencia al utilizar las estructuras de datos *sparse*?\n",
    "\n",
    "R: Los datos se muestran en el bloque anterior, hay una gran diferencia ya que las matrices con estructuras de datos *sparse*, solo alamacena los datos no nulos por ende se obtiene una mejora de esta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. (25 puntos)** Suponga ahora que la matriz simétrica $A$ en el algoritmo de *Deflation* es *Sparse*. Notar que luego de calcular el valor y vector propio dominante de $A$, el resultado obtenido para calcular $A_1$:\n",
    "\n",
    "$$\n",
    "    A_1 = A - \\lambda_1\\mathbf{v}_1\\,\\mathbf{v}_1^T,\n",
    "$$\n",
    "\n",
    "**no** necesariamente es una matriz *sparse*. Esto se debe a que la matriz $\\mathbf{v}_1\\mathbf{v}_1^T$ no necesariamente es *sparse* y al restarse con $A$, esta propiedad puede perderse.\n",
    "\n",
    "A pesar de lo anterior, una propiedad importante de *Power Iteration* es que no opera direcamente sobre la matriz, si no que solo es requerida a través del producto **matriz-vector**. Notar que si se desea calcular $A_1\\mathbf{u}$, donde $\\mathbf{u}$ es un vector arbitrario, puede calcularse como\n",
    "\n",
    "$$\n",
    "    A_1\\mathbf{u} \n",
    "    = \\left(A - \\lambda_1\\mathbf{v}_1\\,\\mathbf{v}_1^T\\right)\\mathbf{u}\n",
    "    = A\\mathbf{u} - \\lambda_1 \\mathbf{v}_1 \\left(\\mathbf{v}_1^T\\mathbf{u}\\right).\n",
    "$$\n",
    "\n",
    "De esta manera, no es necesario construir explícitamente la matriz $\\mathbf{v}_1\\mathbf{v}_1^T$. De manera general, la matriz $A_i\\mathbf{u}$ puede calcularse como\n",
    "\n",
    "$$\n",
    "    A_i\\mathbf{u} = A\\mathbf{u} - \\sum_{k = 1}^{i}\\lambda_k \\left( \\mathbf{v}_k^T\\mathbf{u} \\right) \\mathbf{v}_k.\n",
    "$$\n",
    "\n",
    "Implemente la función `A_times_vector` que reciba como parámetros: \n",
    "\n",
    "* Una matriz de tipo *sparse*.\n",
    "* Un entero $k$.\n",
    "* Una lista con $k$ valores propios.\n",
    "* Una lista con $k$ vectores propios.\n",
    "* Un vector $\\mathbf{u}$, arbitrario.\n",
    "\n",
    "La función debe retornar el resultado numérico del producto matriz-vector $A_{k}\\mathbf{u}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Implementation of a Deflation matriz-vector product to avoid building non-sparse matrix\n",
    "Input:\n",
    "A - (N x N matrix) A matrix in a sparse format.\n",
    "k - (integer) An integer.\n",
    "k_eig_values - (list) A list with k eigenvalues of A.\n",
    "k_eig_vectors - (list) A list with k eigenvectors of A.\n",
    "u - (array) An arbitrary vector\n",
    "Output:\n",
    "b - (array) The result of a Deflation matrix times u, using the given eigenvalues and eigenvectors.\n",
    "'''\n",
    "def A_times_vector(A, k, k_eig_values, k_eig_vectors, u):\n",
    "    suma = np.zeros(A.shape[0])\n",
    "    for i in range(k):\n",
    "        suma +=k_eig_values[i]*np.dot(k_eig_vectors[i].T,u)*k_eig_vectors[i]\n",
    "    if k!=0:\n",
    "        b = A*u-suma\n",
    "    else:\n",
    "        b = A*u\n",
    "    # b is the result of the matrix-vector product\n",
    "    return b\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. (30 puntos)** Implemente la función `sparse_deflation`, modificando su implementación inicial de *Deflation*, que permita operar sobre matrices de gran dimenensión y que sean *sparse*. Para esto, utilice la implementación realizada de la función `A_times_vector` en combinación con el algoritmo de *Power Iteration*. La función `sparse_deflation` recibe como parámetros:\n",
    "* La matriz $A$ de tipo *sparse*.\n",
    "* El *initial guess* $\\mathbf{x}_0$.\n",
    "* El número de iteraciones a realizar en *Power Iteration*\n",
    "* Un número $T$ que indique el número de valores y vectores propios que se desean obtener de la matriz $A$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def power_iteration2(A, x, it,k,k_eig_values, k_eig_vectors,verbose=False):\n",
    "   \n",
    "    for j in range(it):\n",
    "        u = x/np.linalg.norm(x)\n",
    "        x = A_times_vector(A, k, k_eig_values, k_eig_vectors, u)\n",
    "    lam = np.dot(u, x)\n",
    "    u = x/np.linalg.norm(x)\n",
    "    return (lam, u)\n",
    "'''\n",
    "Compute T eigenvalues and eigenvectors from the sparse matrix A, using Deflation.\n",
    "Input:\n",
    "A - (n x n matrix) Sparse matrix\n",
    "x0 - (array) Initial guess for Power Iteration\n",
    "it - (integer) Number of iterations for Power Iteration\n",
    "T - (integer) Number of eigenvalues and eigenvectors to compute from A\n",
    "Output:\n",
    "eig_values - (list) List of T eigenvalues found by the algorithm\n",
    "eig_vectors - (list) List of T eigenvectors found by the algorithm\n",
    "'''\n",
    "def sparse_deflation(A, x0, it, T):\n",
    "    eig_values = []\n",
    "    eig_vectors = []\n",
    "    lam = 0\n",
    "    v = 0\n",
    "    for k in range(T):\n",
    "        lam,v = power_iteration2(A, x0, it,k,eig_values,eig_vectors)\n",
    "        eig_values.append(lam)\n",
    "        eig_vectors.append(v)\n",
    "    return eig_values, eig_vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplique la función `sparse_deflation` sobre las matrices cargadas desde los archivos adjuntos, para distintos valores de $T$ y de iteraciones para *Power Iteration*. Mida los tiempos de ejecución y concluya al respecto. ¿Podría haber aplicado el algoritmo NSI para estas matrices? Justifique y concluya al respecto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de:  10000 x 10000 sparse\n",
      "Tiempo:  0:00:16.923438  para sparse_deflation con  10  iteraciones de Power Iteration y  10 valores distnitos\n",
      "Matriz de:  10000 x 10000 sparse\n",
      "Tiempo:  0:00:33.315545  para sparse_deflation con  10  iteraciones de Power Iteration y  20 valores distnitos\n",
      "Matriz de:  10000 x 10000 sparse\n",
      "Tiempo:  0:00:33.729372  para sparse_deflation con  20  iteraciones de Power Iteration y  10 valores distnitos\n",
      "Matriz de:  10000 x 10000 sparse\n",
      "Tiempo:  0:00:50.594513  para sparse_deflation con  30  iteraciones de Power Iteration y  10 valores distnitos\n",
      "Matriz de:  10000 x 10000 sparse\n",
      "Tiempo:  0:00:54.629518  para sparse_deflation con  10  iteraciones de Power Iteration y  30 valores distnitos\n",
      "Matriz de:  20000 x 20000 sparse\n",
      "Tiempo:  0:00:13.696574  para sparse_deflation con  10  iteraciones de Power Iteration y  10 valores distnitos\n",
      "Matriz de:  20000 x 20000 sparse\n",
      "Tiempo:  0:00:30.146547  para sparse_deflation con  10  iteraciones de Power Iteration y  20 valores distnitos\n",
      "Matriz de:  20000 x 20000 sparse\n",
      "Tiempo:  0:00:26.270720  para sparse_deflation con  20  iteraciones de Power Iteration y  10 valores distnitos\n",
      "Matriz de:  20000 x 20000 sparse\n",
      "Tiempo:  0:00:41.888008  para sparse_deflation con  30  iteraciones de Power Iteration y  10 valores distnitos\n",
      "Matriz de:  20000 x 20000 sparse\n",
      "Tiempo:  0:00:43.456191  para sparse_deflation con  10  iteraciones de Power Iteration y  30 valores distnitos\n",
      "Matriz de:  50000 x 50000 sparse\n",
      "Tiempo:  0:00:18.048470  para sparse_deflation con  10  iteraciones de Power Iteration y  10 valores distnitos\n",
      "Matriz de:  50000 x 50000 sparse\n",
      "Tiempo:  0:00:34.692767  para sparse_deflation con  10  iteraciones de Power Iteration y  20 valores distnitos\n",
      "Matriz de:  50000 x 50000 sparse\n",
      "Tiempo:  0:00:34.985927  para sparse_deflation con  20  iteraciones de Power Iteration y  10 valores distnitos\n",
      "Matriz de:  50000 x 50000 sparse\n",
      "Tiempo:  0:00:51.948452  para sparse_deflation con  30  iteraciones de Power Iteration y  10 valores distnitos\n",
      "Matriz de:  50000 x 50000 sparse\n",
      "Tiempo:  0:00:52.496917  para sparse_deflation con  10  iteraciones de Power Iteration y  30 valores distnitos\n"
     ]
    }
   ],
   "source": [
    "#x03=np.ones(M10000.shape[0])\n",
    "#print(M10000.shape[0])\n",
    "#valores3,vectores3=sparse_deflation(M10000,x03,10,10)\n",
    "#print(valores3)\n",
    "def revisar_sparse_deflation(A,it,T):\n",
    "    print(\"Matriz de: \",A.shape[0],\"x\",A.shape[0],\"sparse\")\n",
    "    x0=np.ones(A.shape[0])\n",
    "    ti = time()\n",
    "    values1,vectores1=sparse_deflation(A, x0, it,T)\n",
    "    tf = time()\n",
    "    tiempo = tf-ti\n",
    "    print(\"Tiempo: \",str(datetime.timedelta(seconds=tiempo)),\" para sparse_deflation con \",it,\" iteraciones de Power Iteration y \",T,\"valores distnitos\")\n",
    "\n",
    "revisar_sparse_deflation(M10000,10,10)\n",
    "revisar_sparse_deflation(M10000,10,20)\n",
    "revisar_sparse_deflation(M10000,20,10)\n",
    "revisar_sparse_deflation(M10000,30,10)\n",
    "revisar_sparse_deflation(M10000,10,30)\n",
    "\n",
    "revisar_sparse_deflation(M20000,10,10)\n",
    "revisar_sparse_deflation(M20000,10,20)\n",
    "revisar_sparse_deflation(M20000,20,10)\n",
    "revisar_sparse_deflation(M20000,30,10)\n",
    "revisar_sparse_deflation(M20000,10,30)\n",
    "\n",
    "revisar_sparse_deflation(M50000,10,10)\n",
    "revisar_sparse_deflation(M50000,10,20)\n",
    "revisar_sparse_deflation(M50000,20,10)\n",
    "revisar_sparse_deflation(M50000,30,10)\n",
    "revisar_sparse_deflation(M50000,10,30)\n",
    "#ti = time()\n",
    "#values1=NSI(M10000,10)\n",
    "#tf = time()\n",
    "#tiempo = tf-ti\n",
    "#print(\"Tiempo: \",str(datetime.timedelta(seconds=tiempo)),\" para NSI con \",10,\" iteraciones\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No se logro ejecutar NSI(M10000,10) hasta el final, utilizando 11 gb de memoria en el proceso, esto se debe al calculo ineficiente que hace qr y posiblemente se pierda la propiedad sparse de la matiz en el proceso.\n",
    "\n",
    "Los tiempos mostrados en el bloque anterior, se puede concluir que no tienen mucha diferencia en el tamaño de la matriz, esto se debe a que al ser sparse solo se hace el calculo con los valores no nulos de la matriz, por ende depende de la cantidad de estos valores que tiene cada matriz.\n",
    "\n",
    "No se encontro mucha diferencia entre aumentar el valor de $it$ (iteraciones del Power Iteration) vs aumentar solo el de la cantidad de valores propios, como se puede ver al utilizar una combinacion de 10-30 o 30-10 donde encontrar más valores propios pero menos precisos es solo un poco mas costoso que tener menos valores pero más precisos. Por ende buscar más valores es mas costoso que se más eficiente en la busqueda de estos. Pero si se quiere preciosion y cantidad el costo sube por ambos lados.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Instrucciones:\n",
    "\n",
    "* **Importante, Asegúrese de responder TODO lo que la pregunta pide.**\n",
    "* La estructura de la tarea es la siguiente:\n",
    "     1. Título, nombre de estudiante, email y rol.\n",
    "     2. Responder cada pregunta de forma personal.\n",
    "     5. Referencias. Es muy importante incluir todas las fuentes usadas, de otra forma se considera que lo no se ha citado adecuadamente es su trabajo.\n",
    "* La tarea debe ser realizada en `Jupyter Notebook` (`Python3`) entregado.\n",
    "* Recuerde responder la encuesta en el plazo establecido\n",
    "* Se evaluará la correcta utilización de librerias `NumPy`, `SciPy`, `Matplotlib` y `ipywidgets`, entre otras, así como la **correcta implementación de algoritmos vectorizados**.\n",
    "* **MUY IMPORTANTE** El archivo de entrega debe denominarse TareaN-rol.tar.gz y _notebook_ debe tener como nombre TareaN-rol.ipynb, donde $N$ es el número de la tarea y debe contener un directorio con todos los archivos necesarios para ejecutar el notebook, junto con un archivo README indicando explícitamente las librerías o módulos utilizados, nombre y rol del estudiante. Por cada error en este ambito implicará un descuento de 30 puntos.\n",
    "* El descuento por día de atraso será de $30$ puntos, con un máximo de 1 día de atraso. No se recibirán entregas después de este día.\n",
    "* Debe citar toda fuente de código externo. \n",
    "* El trabajo es personal, no se permite compartir código ni utilizar código de otros, aunque sí se sugiere discutir aspectos generales con sus compañeros.\n",
    "* En caso de sospecha de no cumplimiento de estas instrucciones, se solicitará al involucrado o la involucrada a aclarar la situación. Dependiendo de la justificación se decidirá su calificación, la cual podrá o no ser penalizada.\n",
    "* El no seguir estas instrucciones, implica descuentos en su nota obtenida."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Referencias\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "[1] Sparse matrix, https://en.wikipedia.org/wiki/Sparse_matrix\n",
    "\n",
    "[2] Sparse module, Scipy. https://docs.scipy.org/doc/scipy/reference/sparse.html\n",
    "\n",
    "https://github.com/tclaudioe/Scientific-Computing/blob/master/SC2/U1_EigenWorld.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Tarea4.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
